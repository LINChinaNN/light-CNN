1. MNIST
Learning rate: 0.038
Batch size: 40
Number of epochs: 30

setup network...
conv: in=32x32x1, out=30x30x6
batch-norm: shape=30x30x6
tanh: shape=30x30x6
conv: in=30x30x6, out=28x28x8
batch-norm: shape=28x28x8
tanh: shape=28x28x8
max-pool: in=28x28x8, out=14x14x8
conv: in=14x14x8, out=12x12x16
batch-norm: shape=12x12x16
tanh: shape=12x12x16
conv: in=12x12x16, out=10x10x32
batch-norm: shape=10x10x32
tanh: shape=10x10x32
max-pool: in=10x10x32, out=5x5x32
conv: in=5x5x32, out=3x3x64
batch-norm: shape=3x3x64
tanh: shape=3x3x64
conv: in=3x3x64, out=1x1x128
batch-norm: shape=1x1x128
tanh: shape=1x1x128
fc: in=128, out=10
batch-norm: shape=10x1x1
tanh: shape=10x1x1

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 1/30 using 42.6143s. lr=0.038
train loss=0.0274138. test loss=0.0165855, acc=9773/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 2/30 using 42.1735s. lr=0.038
train loss=0.00914384. test loss=0.175065, acc=5046/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 3/30 using 42.2017s. lr=0.038
train loss=0.00680468. test loss=0.00749668, acc=9905/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 4/30 using 42.2408s. lr=0.038
train loss=0.00562209. test loss=0.00932058, acc=9892/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 5/30 using 42.19s. lr=0.038
train loss=0.00479765. test loss=0.0102524, acc=9840/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 6/30 using 42.0253s. lr=0.038
train loss=0.00427619. test loss=0.00432096, acc=9932/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 7/30 using 42.4848s. lr=0.038
train loss=0.00384792. test loss=0.0139308, acc=9797/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 8/30 using 42.1039s. lr=0.038
train loss=0.00348816. test loss=0.00518282, acc=9920/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 9/30 using 42.0607s. lr=0.038
train loss=0.00314671. test loss=0.00376313, acc=9942/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 10/30 using 42.0192s. lr=0.038
train loss=0.00291849. test loss=0.00413071, acc=9933/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 11/30 using 42.0144s. lr=0.0038
train loss=0.00228182. test loss=0.00310577, acc=9946/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 12/30 using 42.0857s. lr=0.0038
train loss=0.00211805. test loss=0.00305337, acc=9952/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 13/30 using 42.1068s. lr=0.0038
train loss=0.00206392. test loss=0.00304387, acc=9950/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 14/30 using 42.0189s. lr=0.0038
train loss=0.00203534. test loss=0.00306457, acc=9953/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 15/30 using 42.0393s. lr=0.0038
train loss=0.00203811. test loss=0.0030996, acc=9949/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 16/30 using 42.0488s. lr=0.0038
train loss=0.00198066. test loss=0.00301072, acc=9956/10000





2. CIFAR10 87.03%

Learning rate: 0.022
Batch size: 128
Number of epochs: 20

conv: in=32x32x3, out=32x32x32
batch-norm: shape=32x32x32
leaky: shape=32x32x32
conv: in=32x32x32, out=32x32x32
batch-norm: shape=32x32x32
leaky: shape=32x32x32
max-pool: in=32x32x32, out=16x16x32
conv: in=16x16x32, out=16x16x64
batch-norm: shape=16x16x64
leaky: shape=16x16x64
conv: in=16x16x64, out=16x16x64
batch-norm: shape=16x16x64
leaky: shape=16x16x64
max-pool: in=16x16x64, out=8x8x64
conv: in=8x8x64, out=8x8x128
batch-norm: shape=8x8x128
leaky: shape=8x8x128
conv: in=8x8x128, out=8x8x128
batch-norm: shape=8x8x128
leaky: shape=8x8x128
max-pool: in=8x8x128, out=4x4x128
fc: in=2048, out=128
batch-norm: shape=128x1x1
leaky: shape=128x1x1
fc: in=128, out=10
batch-norm: shape=10x1x1
softmax: in=10x1x1, out=10x1x1

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 1/20 using 131.579s. lr=0.000248902
train loss=1.9783. test loss=1.9866, acc=5675/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 2/20 using 132.761s. lr=0.000248902
train loss=1.30745. test loss=1.40563, acc=7260/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 3/20 using 132.098s. lr=0.000248902
train loss=1.07024. test loss=1.23009, acc=7523/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 4/20 using 133.784s. lr=0.000248902
train loss=0.930935. test loss=1.09054, acc=7859/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 5/20 using 131.478s. lr=0.000248902
train loss=0.81803. test loss=1.06123, acc=7915/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 6/20 using 132.64s. lr=0.000248902
train loss=0.72403. test loss=0.948632, acc=8205/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 7/20 using 132.554s. lr=0.000248902
train loss=0.650797. test loss=0.984702, acc=8108/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 8/20 using 133.949s. lr=0.000248902
train loss=0.589429. test loss=0.989003, acc=8058/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 9/20 using 131.612s. lr=2.48902e-05
train loss=0.441443. test loss=0.730237, acc=8660/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 10/20 using 133.275s. lr=2.48902e-05
train loss=0.401025. test loss=0.720769, acc=8666/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 11/20 using 132.4s. lr=2.48902e-05
train loss=0.37861. test loss=0.721783, acc=8647/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 12/20 using 132.964s. lr=2.48902e-05
train loss=0.363178. test loss=0.709527, acc=8687/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 13/20 using 131.554s. lr=2.48902e-05
train loss=0.348746. test loss=0.708975, acc=8676/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 14/20 using 131.298s. lr=2.48902e-05
train loss=0.33902. test loss=0.705265, acc=8695/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 15/20 using 130.464s. lr=2.48902e-05
train loss=0.32345. test loss=0.705639, acc=8703/10000




3. CIFAR10 90.06%

Learning rate: 0.0221
Batch size: 128
Number of epochs: 30

conv: in=32x32x3, out=32x32x32
batch-norm: shape=32x32x32
leaky: shape=32x32x32
conv: in=32x32x32, out=32x32x32
batch-norm: shape=32x32x32
leaky: shape=32x32x32
conv: in=32x32x32, out=32x32x32
batch-norm: shape=32x32x32
leaky: shape=32x32x32
conv: in=32x32x32, out=32x32x32
batch-norm: shape=32x32x32
leaky: shape=32x32x32
concat: in=32x32x32, out=32x32x128
max-pool: in=32x32x128, out=16x16x128
conv: in=16x16x128, out=16x16x128
batch-norm: shape=16x16x128
leaky: shape=16x16x128
conv: in=16x16x128, out=16x16x128
batch-norm: shape=16x16x128
leaky: shape=16x16x128
conv: in=16x16x128, out=16x16x128
batch-norm: shape=16x16x128
leaky: shape=16x16x128
concat: in=16x16x128, out=16x16x512
max-pool: in=16x16x512, out=8x8x512
conv: in=8x8x512, out=8x8x256
batch-norm: shape=8x8x256
leaky: shape=8x8x256
conv: in=8x8x256, out=8x8x256
batch-norm: shape=8x8x256
leaky: shape=8x8x256
conv: in=8x8x256, out=8x8x256
batch-norm: shape=8x8x256
leaky: shape=8x8x256
concat: in=8x8x256, out=8x8x768
max-pool: in=8x8x768, out=4x4x768
fc: in=12288, out=128
batch-norm: shape=128x1x1
leaky: shape=128x1x1
fc: in=128, out=10
batch-norm: shape=10x1x1
softmax: in=10x1x1, out=10x1x1

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 1/30 using 598.653s. lr=0.000250033
train loss=2.09418. test loss=2.06644, acc=5401/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 2/30 using 601.443s. lr=0.000250033
train loss=1.34817. test loss=1.52549, acc=6960/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 3/30 using 604.979s. lr=0.000250033
train loss=1.06078. test loss=1.4617, acc=7061/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 4/30 using 597.894s. lr=0.000250033
train loss=0.88735. test loss=1.18685, acc=7671/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 5/30 using 601.53s. lr=0.000250033
train loss=0.754733. test loss=1.06135, acc=7923/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 6/30 using 600.408s. lr=0.000250033
train loss=0.650378. test loss=0.819715, acc=8439/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 7/30 using 601.901s. lr=0.000250033
train loss=0.561899. test loss=0.888689, acc=8273/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 8/30 using 601.412s. lr=0.000250033
train loss=0.488571. test loss=0.744807, acc=8569/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 9/30 using 597.53s. lr=2.50033e-05
train loss=0.328546. test loss=0.616611, acc=8870/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 10/30 using 603.912s. lr=2.50033e-05
train loss=0.290188. test loss=0.583529, acc=8938/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 11/30 using 602.015s. lr=2.50033e-05
train loss=0.270105. test loss=0.578768, acc=8945/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 12/30 using 601.289s. lr=2.50033e-05
train loss=0.251492. test loss=0.568399, acc=8995/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 13/30 using 601.688s. lr=2.50033e-05
train loss=0.235779. test loss=0.565026, acc=8988/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 14/30 using 602.045s. lr=2.50033e-05
train loss=0.222961. test loss=0.565534, acc=8998/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 15/30 using 598.036s. lr=2.50033e-05
train loss=0.208051. test loss=0.586424, acc=8951/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 16/30 using 597.694s. lr=2.50033e-05
train loss=0.19423. test loss=0.574334, acc=8981/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 17/30 using 602.057s. lr=2.50033e-05
train loss=0.184089. test loss=0.567803, acc=8987/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 18/30 using 602.247s. lr=2.50033e-05
train loss=0.170984. test loss=0.567158, acc=8991/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 19/30 using 597.746s. lr=2.50033e-05
train loss=0.160317. test loss=0.588876, acc=8955/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 20/30 using 602.323s. lr=2.50033e-05
train loss=0.150778. test loss=0.567897, acc=8980/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 21/30 using 602.466s. lr=2.50033e-05
train loss=0.138949. test loss=0.577047, acc=8985/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 22/30 using 602.383s. lr=2.50033e-05
train loss=0.130938. test loss=0.581445, acc=8983/10000

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
epoch 23/30 using 597.924s. lr=2.50033e-05
train loss=0.119263. test loss=0.571956, acc=9006/10000
